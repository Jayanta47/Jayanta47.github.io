---
title:          "Social Bias in Large Language Models For Bangla: An Empirical Study on Gender and Religious Bias"
date:           2024-07-03 00:01:00 +0800
# selected:       true
# pub:            "5th Workshop on Gender Bias in Natural Language Processing at ACL 2024"
# pub_pre:        "Accepted in "
# pub_post:       'Undergraduate Thesis'
# pub_last:       ' <span class="badge badge-pill badge-publication badge-success">Spotlight</span>'
pub_date:       "May 2024 - July 2024"

supervisor:     
- Dr. Rifat Shahriyar (Professor, BUET)

abstract: >-
  The rapid growth of Large Language Models (LLMs) has put forward the study of biases as a crucial field. It is important to assess the influence of different types of biases embedded in LLMs to ensure fair use in sensitive fields. Although there have been extensive works on bias assessment in English, such efforts are rare and scarce for a major language like Bangla. In this work, we examine two types of social biases in LLM generated outputs for Bangla language. Our main contributions in this work are: (1) bias studies on two different social biases for Bangla (2) a curated dataset for bias measurement benchmarking (3) two different probing techniques for bias detection in the context of Bangla. This is the first work of such kind involving bias assessment of LLMs for Bangla to the best of our knowledge. All our code and resources are publicly available for the progress of bias related research in Bangla NLP.
cover:          https://miro.medium.com/v2/resize:fit:1400/1*7bDJM0kRVmQ9Bm-sln-cLQ.png
authors:
  - Jayanta Sadhu 
  - Maneesha Rani Saha
  - Dr. Rifat Shahriyar (Professor, BUET)
keywords:
    - LLM
    - Bangla Gender Bias
    - Bangla Religious Bias
    - Ethics
    - Fairness
links:
  Paper: https://arxiv.org/pdf/2407.03536
  Code: https://github.com/csebuetnlp/BanglaSocialBias

---